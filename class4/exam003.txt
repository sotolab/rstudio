# 연관어 분석

# 1 단어 추출
> setwd("C:/workspace/rstudio-master/data")
> marketing <- file("013marketing.txt", encoding = "UTF-8")
> marketing2 <- readLines(marketing)
> close(marketing)
> head(marketing2)

# 2 줄 단위 단어 추출
> lword <- Map(extractNoun, marketing2)
> length(lword)
> lword <- unique(lword)
> length(lword)
[1] 353

# 3 중복 단어 제거와 추출 단어 확인
> lword <- sapply(lword, unique)
> length(lword)
> lword

# 4 전처리
> filter1 <- function(x) {
+ nchar(x) <= 4 && nchar(x) >= 2 && is.hangul(x)
+ }
> 
> filter2 <- function(x) { Filter(filter1, x) }


# 5 필터링 함수 정의
> word <- list(c("홍길동", "이순", "만기", "김"),
+ c("대한민국", "우리나라대한민구", "한국", "resu"))
> class(word)

> filter1 <- function(x) {
+ nchar(x) <= 4 && nchar(x) >= 2 && is.hangul(x)
+ }
> filter2 <- function(x) {
+ Filter(filter1, x)
+ }

> filterword <- sapply(word, filter2)
> filterword
[[1]]
[1] "홍길동" "이순"   "만기"  

[[2]]
[1] "대한민국" "한국"    

> 

# 6 트랜잭션 생성
# as : 트랜잭션 생성
# apriori(data, parameter = NULL, appearance = NULL, control = NULL)
# parameter-supp : 지지도(support)
#          -conf : 신뢰도(confidence)
# appearance : 연관규칙 속성
# control : 정렬
> library(arules)
> wordtran <- as(lword, "transactions")
> wordtran
transactions in sparse format with
 353 transactions (rows) and
 2423 items (columns)
>
> tranrules <- apriori(wordtran, 
+ parameter = list(supp = 0.25, conf = 0.05))
> detach(package:tm, unload=TRUE)
> inspect(tranrules)
     lhs                rhs      support   confidence coverage  lift     count
[1]  {}              => {투자}   0.2861190 0.2861190  1.0000000 1.000000 101  







> install.packages("httr")


